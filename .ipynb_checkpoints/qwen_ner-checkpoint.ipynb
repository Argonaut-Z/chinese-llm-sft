{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名实体识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据预处理\n",
    "原始数据如下：\n",
    "```json\n",
    "{\"instruction\": \"你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\\\"entity_text\\\": \\\"南京\\\", \\\"entity_label\\\": \\\"地理实体\\\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\\\"没有找到任何实体\\\". \", \"input\": \"文本:菲律宾总统埃斯特拉达２号透过马尼拉当地电台宣布说，在仍遭到激进的回教阿卜沙耶夫组织羁押在非国南部和落岛的１６名人质当中，军方已经营救出了１１名菲律宾人质。\", \"output\": \"{\\\"entity_text\\\": \\\"菲律宾\\\", \\\"entity_label\\\": \\\"地理实体\\\"}{\\\"entity_text\\\": \\\"埃斯特拉达\\\", \\\"entity_label\\\": \\\"人名\\\"}{\\\"entity_text\\\": \\\"马尼拉\\\", \\\"entity_label\\\": \\\"地理实体\\\"}{\\\"entity_text\\\": \\\"阿卜沙耶夫\\\", \\\"entity_label\\\": \\\"人名\\\"}{\\\"entity_text\\\": \\\"非国\\\", \\\"entity_label\\\": \\\"地理实体\\\"}{\\\"entity_text\\\": \\\"和落岛\\\", \\\"entity_label\\\": \\\"地点\\\"}{\\\"entity_text\\\": \\\"菲律宾\\\", \\\"entity_label\\\": \\\"地理实体\\\"}\"}\n",
    "```\n",
    "```json\n",
    "{\"text\": \"菲律宾总统埃斯特拉达２号透过马尼拉当地电台宣布说，在仍遭到激进的回教阿卜沙耶夫组织羁押在非国南部和落岛的１６名人质当中，军方已经营救出了１１名菲律宾人质。\", \"entities\": [{\"start_idx\": 0, \"end_idx\": 3, \"entity_text\": \"菲律宾\", \"entity_label\": \"GPE\", \"entity_names\": [\"地缘政治实体\", \"政治实体\", \"地理实体\", \"社会实体\"]}, {\"start_idx\": 5, \"end_idx\": 10, \"entity_text\": \"埃斯特拉达\", \"entity_label\": \"PER\", \"entity_names\": [\"人名\", \"姓名\"]}, {\"start_idx\": 14, \"end_idx\": 17, \"entity_text\": \"马尼拉\", \"entity_label\": \"GPE\", \"entity_names\": [\"地缘政治实体\", \"政治实体\", \"地理实体\", \"社会实体\"]}, {\"start_idx\": 34, \"end_idx\": 39, \"entity_text\": \"阿卜沙耶夫\", \"entity_label\": \"PER\", \"entity_names\": [\"人名\", \"姓名\"]}, {\"start_idx\": 44, \"end_idx\": 46, \"entity_text\": \"非国\", \"entity_label\": \"GPE\", \"entity_names\": [\"地缘政治实体\", \"政治实体\", \"地理实体\", \"社会实体\"]}, {\"start_idx\": 48, \"end_idx\": 51, \"entity_text\": \"和落岛\", \"entity_label\": \"LOC\", \"entity_names\": [\"地址\", \"地点\", \"地名\"]}, {\"start_idx\": 71, \"end_idx\": 74, \"entity_text\": \"菲律宾\", \"entity_label\": \"GPE\", \"entity_names\": [\"地缘政治实体\", \"政治实体\", \"地理实体\", \"社会实体\"]}], \"data_source\": \"CCFBDCI\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def dataset_jsonl_transfer(origin_path, new_path):\n",
    "    \"\"\"\n",
    "    将原始数据集转换为大模型微调所需数据格式的新数据集\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    # 读取旧的JSONL文件\n",
    "    with open(origin_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # 解析每一行的json数据\n",
    "            data = json.loads(line)\n",
    "            input_text = data[\"text\"]\n",
    "            entities = data[\"entities\"]\n",
    "            match_names = [\"地点\", \"人名\", \"地理实体\", \"组织\"]\n",
    "            \n",
    "            entity_sentence = \"\"\n",
    "            for entity in entities:\n",
    "                entity_json = dict(entity)\n",
    "                entity_text = entity_json[\"entity_text\"]\n",
    "                entity_names = entity_json[\"entity_names\"]\n",
    "                for name in entity_names:\n",
    "                    if name in match_names:\n",
    "                        entity_label = name\n",
    "                        break\n",
    "                # 最外面的2层{}是为了输出普通的{}\n",
    "                entity_sentence += f\"\"\"{{\"entity_text\": \"{entity_text}\", \"entity_label\": \"{entity_label}\"}}\"\"\"\n",
    "            if entity_sentence == \"\":\n",
    "                entity_sentence = \"没有找到任何实体\"\n",
    "            \n",
    "            message = {\n",
    "                \"instruction\": \"\"\"你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". \"\"\",\n",
    "                \"input\": f\"文本:{input_text}\",\n",
    "                \"output\": entity_sentence,\n",
    "            }\n",
    "            \n",
    "            messages.append(message)\n",
    "    # 保存重构后的JSONL文件\n",
    "    with open(new_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for message in messages:\n",
    "            file.write(json.dumps(message, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# 加载、处理数据集和测试集\n",
    "train_dataset_path = \"data/chinese_ner_sft/ccfbdci.jsonl\"\n",
    "train_jsonl_new_path = \"data/chinese_ner_sft/ccf_train.jsonl\"\n",
    "\n",
    "if not os.path.exists(train_jsonl_new_path):\n",
    "    dataset_jsonl_transfer(train_dataset_path, train_jsonl_new_path)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"entity\": \"人名\"}\n"
     ]
    }
   ],
   "source": [
    "name = \"人名\"\n",
    "string = f\"\"\"{{\"entity\": \"{name}\"}}\"\"\"\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 数据加载和模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 初始化模型和分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from modelscope import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# 加载模型和分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained('./qwen/Qwen2.5-1.5B-Instruct/', use_fast=False, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained('./qwen/Qwen2.5-1.5B-Instruct/', device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model.enable_input_require_grads()  # 开启梯度检查点时，要执行该方法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 预处理训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function process_func at 0x000001C37218E8B0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c79538a3e4e50bb1f07909a9cb6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14152 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 预处理训练数据\n",
    "def process_func(example):\n",
    "    \"\"\"\n",
    "    将数据集进行预处理，处理成模型可以接受的格式\n",
    "    \"\"\"\n",
    "    \n",
    "    MAX_LENGTH = 384\n",
    "    input_ids, attention_mask, lables = [], [], []\n",
    "    system_prompt = \"\"\"你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\".\"\"\"\n",
    "    \n",
    "    instruction = tokenizer(\n",
    "        f\"<|im_start|>system\\n{system_prompt}<|im_end|>\\n<|im_start|>user\\n{example['input']}<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "        add_special_tokens=False,\n",
    "    )\n",
    "    response = tokenizer(f\"{example['output']}\", add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.pad_token_id]\n",
    "    attention_mask = (\n",
    "        instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    )\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.pad_token_id]  # teacher-forcing-training\n",
    "    if len(input_ids) > MAX_LENGTH:     # 做一个截断\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}\n",
    "\n",
    "train_jsonl_new_path = \"data/chinese_ner_sft/ccf_train.jsonl\"\n",
    "\n",
    "total_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_df = total_df[int(len(total_df) * 0.1):]  # 取90%的数据做训练集\n",
    "test_df = total_df[:int(len(total_df) * 0.1)].sample(n=20)  # 随机取10%的数据中的20条做测试集\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_ds.map(process_func, remove_columns=train_ds.column_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 模型微调和训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 设置Lora参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 LoRA（低秩适配）参数\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,   # 任务类型是语言模型\n",
    "    target_modules=[    # 指定 LoRA 需要应用的模块\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    "    inference_mode=False,   # 设置为 False 表示训练模式\n",
    "    r=8,    # Lora 的秩\n",
    "    lora_alpha=32,  # LoRA Alpha，控制低秩适配的比例\n",
    "    lora_dropout=0.1,   # Dropout 比例\n",
    ")\n",
    "\n",
    "# 获取带有 LoRA 配置的模型\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./output/Qwen2.5-NER\",  # 输出目录\n",
    "    per_device_train_batch_size=4,  # 每设备训练的批次大小\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,  # 梯度累积步数\n",
    "    logging_steps=10,  # 每隔多少步记录一次日志\n",
    "    num_train_epochs=2,  # 训练轮数\n",
    "    save_steps=100,  # 每隔多少步保存一次模型\n",
    "    learning_rate=1e-4,  # 学习率\n",
    "    save_on_each_node=True,  # 每个节点保存模型\n",
    "    gradient_checkpointing=True,  # 启用梯度检查点\n",
    "    report_to=\"none\",  # 不报告到任何平台\n",
    ")\n",
    "\n",
    "from swanlab.integration.huggingface import SwanLabCallback\n",
    "import swanlab\n",
    "\n",
    "swanlab_callback = SwanLabCallback(\n",
    "    project=\"Qwen2.5-NER-fintune\",\n",
    "    experiment_name=\"Qwen2.5-1.5B-Instruct-ner-lora\",\n",
    "    description=\"使用通义千问Qwen2.5-1.5B-Instruct模型在NER数据集上微调，实现关键实体识别任务。\",\n",
    "    config={\n",
    "        \"model\": \"qwen/Qwen2.5-1.5B-Instruct\",\n",
    "        \"dataset\": \"qgyd2021/chinese_ner_sft\",\n",
    "    },\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    callbacks=[swanlab_callback],\n",
    ")\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 加载LoRA微调后的模型\n",
    "LoRA 的微调实际上是将新的参数添加到模型中，因此你需要加载原始基座模型（Qwen2）并同时加载 LoRA 调整后的参数。你可以通过以下代码加载微调后的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# 设定模型路径和输出目录\n",
    "model_name = './qwen/Qwen2.5-1.5B-Instruct/'  # 这是基座模型路径\n",
    "output_dir = './output/Qwen2.5-NER/checkpoint-1768/'  # 这是保存微调后模型的输出目录\n",
    "\n",
    "# 加载 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# 加载基座模型\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# 设置 LoRA 配置\n",
    "lora_config = LoraConfig.from_pretrained(output_dir)  # 加载 LoRA 配置\n",
    "\n",
    "# 使用 LoRA 调整模型\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 将模型加载到 GPU 或 CPU\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 推理时使用微调后的模型\n",
    "加载了微调后的模型后，你可以像正常使用任何预训练模型一样使用它进行推理。以下是一个简单的推理过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"entity_text\":\"王新平\",\"entity_label\":\"人名\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:而最后结论，王新平强调，一切交由大法官决定。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"王新平\",\"entity_label\":\"人名\"}'}\n",
      "{\"entity_text\":\"迪斯尼\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:我们乘坐出租车沿着通往迪斯尼方向的公路一路向前，'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"迪斯尼\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:对。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有实体\"}'}\n",
      "{\"entity_text\":\"菲律宾中正学院\",\"entity_label\":\"组织实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:另外侨务委员会委员长张富美今天接见了菲律宾中正学院代表团时表示，侨务政策有一贯性，不会因为政党轮替而有所偏移。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"菲律宾中正学院\",\"entity_label\":\"组织实体\"}'}\n",
      "{\"entity_text\":\"台北国际之声\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:这里是《ｃｂｓ台北国际之声》新闻广播网。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"台北国际之声\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有找到任何实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:所以大陆科学研究的产出，高新技术产业的竞争力都落后于发达国家。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有找到任何实体\"}'}\n",
      "{\"entity_text\": \"南京\", \"entity_label\": \"地点\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:随同金正日到访的包括北韩的高阶军事将领和经济官员，金正日在去年５月２９号到３１号，也就是在平壤跟南韩总统金大中展开历史性高峰会谈的信息，前往大陆访问听取北京的意见。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\": \"南京\", \"entity_label\": \"地点\"}'}\n",
      "{\"entity_text\":\"非洲\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:非洲严重的艾滋病问题引起了非洲和世界各国的关注。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"非洲\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\":\"台湾\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:不过曾胜海认为，根据去年一年大陆地区人民出国观光的总人数就高达９００万人次，并且他们也对当地民众做过多次民调，其中希望能够来台旅游的比例超过半数以上，再加上依照国内目前的旅馆客房总数，每年开放１００万大陆人士来台观光绝对不是问题。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"台湾\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\":\"EMTPY\",\"entity_label\":\"组织实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:ＥＭＰＴＹ'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"EMTPY\",\"entity_label\":\"组织实体\"}'}\n",
      "{\"entity_text\":\"美国\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:信息中心说：美国将人权问题作为外交政策中的核心策略，但是如果美国本身不能够依照联合国的人权公约内容来保障遭到中共迫害的人士，将会令人感到非常的失望。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"美国\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\":\"南京\",\"entity_label\":\"地点\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:头奖是美金３００元，二奖２００元，三奖１００元，另外还有高级手表、短波收音机、计算机、茶杯垫等５００个奖项。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"南京\",\"entity_label\":\"地点\"}'}\n",
      "{\"entity_text\": \"平壤\", \"entity_label\": \"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:朴在归说：“南北韩之间有关于经济和离散家庭重聚的会谈已经延期，北韩这个星期全部精力都集中在举办共产党执政５５周年以及迎接美国国务卿奥尔布赖特前往平壤访问的庆祝活动。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\": \"平壤\", \"entity_label\": \"地理实体\"}'}\n",
      "{\"entity_text\":\"自然资源\", \"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:自然资源相对缺乏，'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"自然资源\", \"entity_label\":\"地理实体\"}'}\n",
      "[{\"entity_text\": \"东莞台商子弟学校\", \"entity_label\": \"组织\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:东莞台商子弟学校，还特地选出了国小一年二班陈伊玲、三年一班郭建良、四年一班张维涵和国中部三年一班的李维珍等四位小朋友写给部长爷爷，教育部长曾志朗和次长阿姨政务司长范徐丽的感谢信，以及李维珍和张维涵写给创校有功的伯伯叔叔和阿姨的一封信，文辞都相当的感人。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '[{\"entity_text\": \"东莞台商子弟学校\", \"entity_label\": \"组织\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二班陈伊玲\", \"entity_label\": \"人名\"}, {\"entity_text\": \"国小一年二'}\n",
      "{\"entity_text\":\"以巴\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:最近１０个星期的以巴严重冲突已经造成了３００多人丧生，其中大部分是巴勒斯坦人。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"以巴\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\": \"司改会\", \"entity_label\": \"组织实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:民间司改会执行长王学思表示，他们呼吁司务部、司法院紧速建立淘汰不适任法官的机制，建订《法官法》，打破法官一律终身制的作法，以及建立法官、检察官律师的官方评建机制。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\": \"司改会\", \"entity_label\": \"组织实体\"}'}\n",
      "{\"entity_text\":\"菲律宾\",\"entity_label\":\"地理实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:戒备森严的菲律宾参议院７号在２０员议员到场的情况之下主席宣布正式开庭。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"菲律宾\",\"entity_label\":\"地理实体\"}'}\n",
      "{\"entity_text\": \"李前\", \"entity_label\": \"人名\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:在李前总统开刀的消息方面。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\": \"李前\", \"entity_label\": \"人名\"}'}\n",
      "{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有找到任何实体\"}\n",
      "{'role': 'system', 'content': '你是一个文本实体识别领域的专家，你需要从给定的句子中提取 地点; 人名; 地理实体; 组织 实体. 以 json 格式输出, 如 {\"entity_text\": \"南京\", \"entity_label\": \"地理实体\"} 注意: 1. 输出的每一行都必须是正确的 json 字符串. 2. 找不到任何实体时, 输出\"没有找到任何实体\". '}\n",
      "\n",
      "{'role': 'user', 'content': '文本:首先一起来关注今天节目的主要内容。'}\n",
      "\n",
      "{'role': 'assistant', 'content': '{\"entity_text\":\"没有找到任何实体\",\"entity_label\":\"没有找到任何实体\"}'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 在需要释放内存的地方添加以下命令\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "train_jsonl_new_path = \"data/chinese_ner_sft/ccf_train.jsonl\"\n",
    "\n",
    "total_df = pd.read_json(train_jsonl_new_path, lines=True)\n",
    "train_df = total_df[int(len(total_df) * 0.1):]  # 取90%的数据做训练集\n",
    "test_df = total_df[:int(len(total_df) * 0.1)].sample(n=20)  # 随机取10%的数据中的20条做测试集\n",
    "\n",
    "# 训练结束后的预测\n",
    "# 训练结束后的预测函数\n",
    "def predict(messages, model, tokenizer):\n",
    "    # 设置设备为 CUDA (GPU)，如果使用 GPU 的话\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    # 使用 tokenizer 应用聊天模板，将消息转化为文本，tokenize=False 表示不进行分词\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 将生成的文本转换为模型输入格式，并传输到 GPU 上\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 通过模型生成预测输出，设置生成的最大token数为512\n",
    "    generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=512)\n",
    "    \n",
    "    # 对每个输入文本，截取去掉原始输入部分，保留生成的部分\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):]\n",
    "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    # 解码生成的 token 为文本，skip_special_tokens=True 用来去掉特殊token（如 [CLS], [SEP] 等）\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 打印生成的回复\n",
    "    print(response)\n",
    "    \n",
    "    # 返回生成的回复\n",
    "    return response\n",
    "\n",
    "# 初始化一个列表，用于存储测试结果\n",
    "test_text_list = []\n",
    "\n",
    "# 遍历测试数据集 (test_df)，并使用每一行的 'instruction' 和 'input' 构建消息\n",
    "for index, row in test_df.iterrows():\n",
    "    instruction = row[\"instruction\"]\n",
    "    input_value = row[\"input\"]\n",
    "\n",
    "    # 根据 'instruction' 和 'input' 构建消息结构\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"{instruction}\"},  # 系统角色，提供任务指令\n",
    "        {\"role\": \"user\", \"content\": f\"{input_value}\"},    # 用户角色，提供输入\n",
    "    ]\n",
    "\n",
    "    # 调用 predict 函数生成回复\n",
    "    response = predict(messages, model, tokenizer)\n",
    "    \n",
    "    # 将生成的回复添加为 'assistant' 角色的内容\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f\"{response}\"})\n",
    "    \n",
    "    # 格式化并将消息、回复保存到结果列表中\n",
    "    result_text = f\"{messages[0]}\\n\\n{messages[1]}\\n\\n{messages[2]}\"\n",
    "    print(result_text)\n",
    "    test_text_list.append(result_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpupytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
