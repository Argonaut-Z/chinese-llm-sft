{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9044657998869418,
  "eval_steps": 500,
  "global_step": 800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011305822498586773,
      "grad_norm": 2.101466178894043,
      "learning_rate": 9.94343891402715e-05,
      "loss": 0.8652,
      "step": 10
    },
    {
      "epoch": 0.022611644997173545,
      "grad_norm": 0.7962708473205566,
      "learning_rate": 9.8868778280543e-05,
      "loss": 0.1242,
      "step": 20
    },
    {
      "epoch": 0.033917467495760314,
      "grad_norm": 1.2894328832626343,
      "learning_rate": 9.830316742081447e-05,
      "loss": 0.1353,
      "step": 30
    },
    {
      "epoch": 0.04522328999434709,
      "grad_norm": 1.6169347763061523,
      "learning_rate": 9.773755656108597e-05,
      "loss": 0.0825,
      "step": 40
    },
    {
      "epoch": 0.05652911249293386,
      "grad_norm": 1.6680057048797607,
      "learning_rate": 9.717194570135747e-05,
      "loss": 0.0849,
      "step": 50
    },
    {
      "epoch": 0.06783493499152063,
      "grad_norm": 1.3571325540542603,
      "learning_rate": 9.660633484162897e-05,
      "loss": 0.0483,
      "step": 60
    },
    {
      "epoch": 0.0791407574901074,
      "grad_norm": 1.1001209020614624,
      "learning_rate": 9.604072398190045e-05,
      "loss": 0.0859,
      "step": 70
    },
    {
      "epoch": 0.09044657998869418,
      "grad_norm": 0.7112443447113037,
      "learning_rate": 9.547511312217195e-05,
      "loss": 0.0913,
      "step": 80
    },
    {
      "epoch": 0.10175240248728094,
      "grad_norm": 0.8780766725540161,
      "learning_rate": 9.490950226244344e-05,
      "loss": 0.0898,
      "step": 90
    },
    {
      "epoch": 0.11305822498586772,
      "grad_norm": 0.6554320454597473,
      "learning_rate": 9.434389140271494e-05,
      "loss": 0.0657,
      "step": 100
    },
    {
      "epoch": 0.1243640474844545,
      "grad_norm": 0.549679160118103,
      "learning_rate": 9.377828054298643e-05,
      "loss": 0.0842,
      "step": 110
    },
    {
      "epoch": 0.13566986998304126,
      "grad_norm": 0.7680590152740479,
      "learning_rate": 9.321266968325792e-05,
      "loss": 0.0659,
      "step": 120
    },
    {
      "epoch": 0.14697569248162803,
      "grad_norm": 0.5673206448554993,
      "learning_rate": 9.264705882352942e-05,
      "loss": 0.079,
      "step": 130
    },
    {
      "epoch": 0.1582815149802148,
      "grad_norm": 0.6351529359817505,
      "learning_rate": 9.20814479638009e-05,
      "loss": 0.0873,
      "step": 140
    },
    {
      "epoch": 0.1695873374788016,
      "grad_norm": 0.6608370542526245,
      "learning_rate": 9.15158371040724e-05,
      "loss": 0.0751,
      "step": 150
    },
    {
      "epoch": 0.18089315997738836,
      "grad_norm": 0.4028741419315338,
      "learning_rate": 9.09502262443439e-05,
      "loss": 0.065,
      "step": 160
    },
    {
      "epoch": 0.19219898247597514,
      "grad_norm": 0.7662176489830017,
      "learning_rate": 9.038461538461538e-05,
      "loss": 0.0443,
      "step": 170
    },
    {
      "epoch": 0.2035048049745619,
      "grad_norm": 0.7876043915748596,
      "learning_rate": 8.981900452488688e-05,
      "loss": 0.07,
      "step": 180
    },
    {
      "epoch": 0.21481062747314866,
      "grad_norm": 0.634654700756073,
      "learning_rate": 8.925339366515838e-05,
      "loss": 0.0782,
      "step": 190
    },
    {
      "epoch": 0.22611644997173544,
      "grad_norm": 0.9381968379020691,
      "learning_rate": 8.868778280542987e-05,
      "loss": 0.0633,
      "step": 200
    },
    {
      "epoch": 0.23742227247032222,
      "grad_norm": 0.17854095995426178,
      "learning_rate": 8.812217194570136e-05,
      "loss": 0.0434,
      "step": 210
    },
    {
      "epoch": 0.248728094968909,
      "grad_norm": 0.9447739124298096,
      "learning_rate": 8.755656108597285e-05,
      "loss": 0.0595,
      "step": 220
    },
    {
      "epoch": 0.26003391746749577,
      "grad_norm": 0.39342811703681946,
      "learning_rate": 8.699095022624435e-05,
      "loss": 0.0602,
      "step": 230
    },
    {
      "epoch": 0.2713397399660825,
      "grad_norm": 0.8482068777084351,
      "learning_rate": 8.642533936651585e-05,
      "loss": 0.0521,
      "step": 240
    },
    {
      "epoch": 0.2826455624646693,
      "grad_norm": 0.6248562335968018,
      "learning_rate": 8.585972850678733e-05,
      "loss": 0.0553,
      "step": 250
    },
    {
      "epoch": 0.29395138496325607,
      "grad_norm": 0.2944934666156769,
      "learning_rate": 8.529411764705883e-05,
      "loss": 0.0475,
      "step": 260
    },
    {
      "epoch": 0.30525720746184287,
      "grad_norm": 0.5206577777862549,
      "learning_rate": 8.472850678733031e-05,
      "loss": 0.0393,
      "step": 270
    },
    {
      "epoch": 0.3165630299604296,
      "grad_norm": 0.6878554224967957,
      "learning_rate": 8.416289592760181e-05,
      "loss": 0.0589,
      "step": 280
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.340130090713501,
      "learning_rate": 8.359728506787331e-05,
      "loss": 0.0564,
      "step": 290
    },
    {
      "epoch": 0.3391746749576032,
      "grad_norm": 0.593849241733551,
      "learning_rate": 8.303167420814481e-05,
      "loss": 0.0395,
      "step": 300
    },
    {
      "epoch": 0.3504804974561899,
      "grad_norm": 0.6631272435188293,
      "learning_rate": 8.24660633484163e-05,
      "loss": 0.05,
      "step": 310
    },
    {
      "epoch": 0.3617863199547767,
      "grad_norm": 0.7049257755279541,
      "learning_rate": 8.190045248868778e-05,
      "loss": 0.0678,
      "step": 320
    },
    {
      "epoch": 0.3730921424533635,
      "grad_norm": 0.5400152802467346,
      "learning_rate": 8.133484162895928e-05,
      "loss": 0.0558,
      "step": 330
    },
    {
      "epoch": 0.3843979649519503,
      "grad_norm": 0.49237412214279175,
      "learning_rate": 8.076923076923078e-05,
      "loss": 0.0517,
      "step": 340
    },
    {
      "epoch": 0.395703787450537,
      "grad_norm": 0.7134804725646973,
      "learning_rate": 8.020361990950228e-05,
      "loss": 0.0626,
      "step": 350
    },
    {
      "epoch": 0.4070096099491238,
      "grad_norm": 0.9317993521690369,
      "learning_rate": 7.963800904977376e-05,
      "loss": 0.0587,
      "step": 360
    },
    {
      "epoch": 0.4183154324477106,
      "grad_norm": 0.9515960216522217,
      "learning_rate": 7.907239819004525e-05,
      "loss": 0.0553,
      "step": 370
    },
    {
      "epoch": 0.4296212549462973,
      "grad_norm": 0.6463990807533264,
      "learning_rate": 7.850678733031674e-05,
      "loss": 0.0526,
      "step": 380
    },
    {
      "epoch": 0.44092707744488413,
      "grad_norm": 0.7403039932250977,
      "learning_rate": 7.794117647058824e-05,
      "loss": 0.0477,
      "step": 390
    },
    {
      "epoch": 0.4522328999434709,
      "grad_norm": 0.47252604365348816,
      "learning_rate": 7.737556561085974e-05,
      "loss": 0.0505,
      "step": 400
    },
    {
      "epoch": 0.4635387224420577,
      "grad_norm": 0.228780135512352,
      "learning_rate": 7.680995475113123e-05,
      "loss": 0.0472,
      "step": 410
    },
    {
      "epoch": 0.47484454494064443,
      "grad_norm": 0.7029057741165161,
      "learning_rate": 7.624434389140271e-05,
      "loss": 0.0508,
      "step": 420
    },
    {
      "epoch": 0.4861503674392312,
      "grad_norm": 0.5056055784225464,
      "learning_rate": 7.567873303167421e-05,
      "loss": 0.0871,
      "step": 430
    },
    {
      "epoch": 0.497456189937818,
      "grad_norm": 0.2992648184299469,
      "learning_rate": 7.511312217194571e-05,
      "loss": 0.0523,
      "step": 440
    },
    {
      "epoch": 0.5087620124364047,
      "grad_norm": 0.5108587741851807,
      "learning_rate": 7.45475113122172e-05,
      "loss": 0.0401,
      "step": 450
    },
    {
      "epoch": 0.5200678349349915,
      "grad_norm": 0.5572494864463806,
      "learning_rate": 7.398190045248869e-05,
      "loss": 0.0487,
      "step": 460
    },
    {
      "epoch": 0.5313736574335783,
      "grad_norm": 0.40040937066078186,
      "learning_rate": 7.341628959276018e-05,
      "loss": 0.0523,
      "step": 470
    },
    {
      "epoch": 0.542679479932165,
      "grad_norm": 0.4428374767303467,
      "learning_rate": 7.285067873303167e-05,
      "loss": 0.051,
      "step": 480
    },
    {
      "epoch": 0.5539853024307518,
      "grad_norm": 0.5894176363945007,
      "learning_rate": 7.228506787330317e-05,
      "loss": 0.0551,
      "step": 490
    },
    {
      "epoch": 0.5652911249293386,
      "grad_norm": 0.5254224538803101,
      "learning_rate": 7.171945701357467e-05,
      "loss": 0.0538,
      "step": 500
    },
    {
      "epoch": 0.5765969474279253,
      "grad_norm": 0.503007173538208,
      "learning_rate": 7.115384615384616e-05,
      "loss": 0.0361,
      "step": 510
    },
    {
      "epoch": 0.5879027699265121,
      "grad_norm": 0.20366744697093964,
      "learning_rate": 7.058823529411765e-05,
      "loss": 0.038,
      "step": 520
    },
    {
      "epoch": 0.5992085924250989,
      "grad_norm": 0.41521114110946655,
      "learning_rate": 7.002262443438914e-05,
      "loss": 0.0606,
      "step": 530
    },
    {
      "epoch": 0.6105144149236857,
      "grad_norm": 0.7440342307090759,
      "learning_rate": 6.945701357466064e-05,
      "loss": 0.0503,
      "step": 540
    },
    {
      "epoch": 0.6218202374222724,
      "grad_norm": 0.5117661356925964,
      "learning_rate": 6.889140271493212e-05,
      "loss": 0.0592,
      "step": 550
    },
    {
      "epoch": 0.6331260599208592,
      "grad_norm": 0.20890899002552032,
      "learning_rate": 6.832579185520362e-05,
      "loss": 0.0394,
      "step": 560
    },
    {
      "epoch": 0.644431882419446,
      "grad_norm": 0.37216317653656006,
      "learning_rate": 6.776018099547512e-05,
      "loss": 0.0333,
      "step": 570
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.5263232588768005,
      "learning_rate": 6.719457013574662e-05,
      "loss": 0.0351,
      "step": 580
    },
    {
      "epoch": 0.6670435274166195,
      "grad_norm": 0.3571467697620392,
      "learning_rate": 6.66289592760181e-05,
      "loss": 0.0314,
      "step": 590
    },
    {
      "epoch": 0.6783493499152063,
      "grad_norm": 1.1849251985549927,
      "learning_rate": 6.606334841628959e-05,
      "loss": 0.0558,
      "step": 600
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.6529349088668823,
      "learning_rate": 6.549773755656109e-05,
      "loss": 0.0432,
      "step": 610
    },
    {
      "epoch": 0.7009609949123798,
      "grad_norm": 0.5217703580856323,
      "learning_rate": 6.493212669683258e-05,
      "loss": 0.057,
      "step": 620
    },
    {
      "epoch": 0.7122668174109666,
      "grad_norm": 0.4615226089954376,
      "learning_rate": 6.436651583710408e-05,
      "loss": 0.0292,
      "step": 630
    },
    {
      "epoch": 0.7235726399095535,
      "grad_norm": 0.7857714295387268,
      "learning_rate": 6.380090497737557e-05,
      "loss": 0.0478,
      "step": 640
    },
    {
      "epoch": 0.7348784624081401,
      "grad_norm": 0.633795976638794,
      "learning_rate": 6.323529411764705e-05,
      "loss": 0.0408,
      "step": 650
    },
    {
      "epoch": 0.746184284906727,
      "grad_norm": 0.5846021175384521,
      "learning_rate": 6.266968325791855e-05,
      "loss": 0.0534,
      "step": 660
    },
    {
      "epoch": 0.7574901074053138,
      "grad_norm": 0.8379735946655273,
      "learning_rate": 6.210407239819005e-05,
      "loss": 0.0468,
      "step": 670
    },
    {
      "epoch": 0.7687959299039006,
      "grad_norm": 0.4669826328754425,
      "learning_rate": 6.153846153846155e-05,
      "loss": 0.0532,
      "step": 680
    },
    {
      "epoch": 0.7801017524024872,
      "grad_norm": 0.5057278871536255,
      "learning_rate": 6.097285067873304e-05,
      "loss": 0.0364,
      "step": 690
    },
    {
      "epoch": 0.791407574901074,
      "grad_norm": 0.45614245533943176,
      "learning_rate": 6.0407239819004525e-05,
      "loss": 0.0392,
      "step": 700
    },
    {
      "epoch": 0.8027133973996609,
      "grad_norm": 0.40115416049957275,
      "learning_rate": 5.984162895927602e-05,
      "loss": 0.0431,
      "step": 710
    },
    {
      "epoch": 0.8140192198982475,
      "grad_norm": 0.5991466641426086,
      "learning_rate": 5.9276018099547516e-05,
      "loss": 0.0521,
      "step": 720
    },
    {
      "epoch": 0.8253250423968344,
      "grad_norm": 0.5092165470123291,
      "learning_rate": 5.871040723981901e-05,
      "loss": 0.0518,
      "step": 730
    },
    {
      "epoch": 0.8366308648954212,
      "grad_norm": 0.4294959306716919,
      "learning_rate": 5.8144796380090506e-05,
      "loss": 0.0383,
      "step": 740
    },
    {
      "epoch": 0.847936687394008,
      "grad_norm": 0.624837338924408,
      "learning_rate": 5.757918552036199e-05,
      "loss": 0.0492,
      "step": 750
    },
    {
      "epoch": 0.8592425098925947,
      "grad_norm": 0.6146548390388489,
      "learning_rate": 5.701357466063348e-05,
      "loss": 0.0527,
      "step": 760
    },
    {
      "epoch": 0.8705483323911815,
      "grad_norm": 0.4858262836933136,
      "learning_rate": 5.644796380090498e-05,
      "loss": 0.0365,
      "step": 770
    },
    {
      "epoch": 0.8818541548897683,
      "grad_norm": 0.5251266360282898,
      "learning_rate": 5.588235294117647e-05,
      "loss": 0.0587,
      "step": 780
    },
    {
      "epoch": 0.893159977388355,
      "grad_norm": 0.6133573055267334,
      "learning_rate": 5.531674208144797e-05,
      "loss": 0.0355,
      "step": 790
    },
    {
      "epoch": 0.9044657998869418,
      "grad_norm": 0.6339415311813354,
      "learning_rate": 5.475113122171946e-05,
      "loss": 0.0483,
      "step": 800
    }
  ],
  "logging_steps": 10,
  "max_steps": 1768,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7521353527279616e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
