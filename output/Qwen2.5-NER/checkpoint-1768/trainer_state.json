{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.998304126625212,
  "eval_steps": 500,
  "global_step": 1768,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011305822498586773,
      "grad_norm": 2.101466178894043,
      "learning_rate": 9.94343891402715e-05,
      "loss": 0.8652,
      "step": 10
    },
    {
      "epoch": 0.022611644997173545,
      "grad_norm": 0.7962708473205566,
      "learning_rate": 9.8868778280543e-05,
      "loss": 0.1242,
      "step": 20
    },
    {
      "epoch": 0.033917467495760314,
      "grad_norm": 1.2894328832626343,
      "learning_rate": 9.830316742081447e-05,
      "loss": 0.1353,
      "step": 30
    },
    {
      "epoch": 0.04522328999434709,
      "grad_norm": 1.6169347763061523,
      "learning_rate": 9.773755656108597e-05,
      "loss": 0.0825,
      "step": 40
    },
    {
      "epoch": 0.05652911249293386,
      "grad_norm": 1.6680057048797607,
      "learning_rate": 9.717194570135747e-05,
      "loss": 0.0849,
      "step": 50
    },
    {
      "epoch": 0.06783493499152063,
      "grad_norm": 1.3571325540542603,
      "learning_rate": 9.660633484162897e-05,
      "loss": 0.0483,
      "step": 60
    },
    {
      "epoch": 0.0791407574901074,
      "grad_norm": 1.1001209020614624,
      "learning_rate": 9.604072398190045e-05,
      "loss": 0.0859,
      "step": 70
    },
    {
      "epoch": 0.09044657998869418,
      "grad_norm": 0.7112443447113037,
      "learning_rate": 9.547511312217195e-05,
      "loss": 0.0913,
      "step": 80
    },
    {
      "epoch": 0.10175240248728094,
      "grad_norm": 0.8780766725540161,
      "learning_rate": 9.490950226244344e-05,
      "loss": 0.0898,
      "step": 90
    },
    {
      "epoch": 0.11305822498586772,
      "grad_norm": 0.6554320454597473,
      "learning_rate": 9.434389140271494e-05,
      "loss": 0.0657,
      "step": 100
    },
    {
      "epoch": 0.1243640474844545,
      "grad_norm": 0.549679160118103,
      "learning_rate": 9.377828054298643e-05,
      "loss": 0.0842,
      "step": 110
    },
    {
      "epoch": 0.13566986998304126,
      "grad_norm": 0.7680590152740479,
      "learning_rate": 9.321266968325792e-05,
      "loss": 0.0659,
      "step": 120
    },
    {
      "epoch": 0.14697569248162803,
      "grad_norm": 0.5673206448554993,
      "learning_rate": 9.264705882352942e-05,
      "loss": 0.079,
      "step": 130
    },
    {
      "epoch": 0.1582815149802148,
      "grad_norm": 0.6351529359817505,
      "learning_rate": 9.20814479638009e-05,
      "loss": 0.0873,
      "step": 140
    },
    {
      "epoch": 0.1695873374788016,
      "grad_norm": 0.6608370542526245,
      "learning_rate": 9.15158371040724e-05,
      "loss": 0.0751,
      "step": 150
    },
    {
      "epoch": 0.18089315997738836,
      "grad_norm": 0.4028741419315338,
      "learning_rate": 9.09502262443439e-05,
      "loss": 0.065,
      "step": 160
    },
    {
      "epoch": 0.19219898247597514,
      "grad_norm": 0.7662176489830017,
      "learning_rate": 9.038461538461538e-05,
      "loss": 0.0443,
      "step": 170
    },
    {
      "epoch": 0.2035048049745619,
      "grad_norm": 0.7876043915748596,
      "learning_rate": 8.981900452488688e-05,
      "loss": 0.07,
      "step": 180
    },
    {
      "epoch": 0.21481062747314866,
      "grad_norm": 0.634654700756073,
      "learning_rate": 8.925339366515838e-05,
      "loss": 0.0782,
      "step": 190
    },
    {
      "epoch": 0.22611644997173544,
      "grad_norm": 0.9381968379020691,
      "learning_rate": 8.868778280542987e-05,
      "loss": 0.0633,
      "step": 200
    },
    {
      "epoch": 0.23742227247032222,
      "grad_norm": 0.17854095995426178,
      "learning_rate": 8.812217194570136e-05,
      "loss": 0.0434,
      "step": 210
    },
    {
      "epoch": 0.248728094968909,
      "grad_norm": 0.9447739124298096,
      "learning_rate": 8.755656108597285e-05,
      "loss": 0.0595,
      "step": 220
    },
    {
      "epoch": 0.26003391746749577,
      "grad_norm": 0.39342811703681946,
      "learning_rate": 8.699095022624435e-05,
      "loss": 0.0602,
      "step": 230
    },
    {
      "epoch": 0.2713397399660825,
      "grad_norm": 0.8482068777084351,
      "learning_rate": 8.642533936651585e-05,
      "loss": 0.0521,
      "step": 240
    },
    {
      "epoch": 0.2826455624646693,
      "grad_norm": 0.6248562335968018,
      "learning_rate": 8.585972850678733e-05,
      "loss": 0.0553,
      "step": 250
    },
    {
      "epoch": 0.29395138496325607,
      "grad_norm": 0.2944934666156769,
      "learning_rate": 8.529411764705883e-05,
      "loss": 0.0475,
      "step": 260
    },
    {
      "epoch": 0.30525720746184287,
      "grad_norm": 0.5206577777862549,
      "learning_rate": 8.472850678733031e-05,
      "loss": 0.0393,
      "step": 270
    },
    {
      "epoch": 0.3165630299604296,
      "grad_norm": 0.6878554224967957,
      "learning_rate": 8.416289592760181e-05,
      "loss": 0.0589,
      "step": 280
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.340130090713501,
      "learning_rate": 8.359728506787331e-05,
      "loss": 0.0564,
      "step": 290
    },
    {
      "epoch": 0.3391746749576032,
      "grad_norm": 0.593849241733551,
      "learning_rate": 8.303167420814481e-05,
      "loss": 0.0395,
      "step": 300
    },
    {
      "epoch": 0.3504804974561899,
      "grad_norm": 0.6631272435188293,
      "learning_rate": 8.24660633484163e-05,
      "loss": 0.05,
      "step": 310
    },
    {
      "epoch": 0.3617863199547767,
      "grad_norm": 0.7049257755279541,
      "learning_rate": 8.190045248868778e-05,
      "loss": 0.0678,
      "step": 320
    },
    {
      "epoch": 0.3730921424533635,
      "grad_norm": 0.5400152802467346,
      "learning_rate": 8.133484162895928e-05,
      "loss": 0.0558,
      "step": 330
    },
    {
      "epoch": 0.3843979649519503,
      "grad_norm": 0.49237412214279175,
      "learning_rate": 8.076923076923078e-05,
      "loss": 0.0517,
      "step": 340
    },
    {
      "epoch": 0.395703787450537,
      "grad_norm": 0.7134804725646973,
      "learning_rate": 8.020361990950228e-05,
      "loss": 0.0626,
      "step": 350
    },
    {
      "epoch": 0.4070096099491238,
      "grad_norm": 0.9317993521690369,
      "learning_rate": 7.963800904977376e-05,
      "loss": 0.0587,
      "step": 360
    },
    {
      "epoch": 0.4183154324477106,
      "grad_norm": 0.9515960216522217,
      "learning_rate": 7.907239819004525e-05,
      "loss": 0.0553,
      "step": 370
    },
    {
      "epoch": 0.4296212549462973,
      "grad_norm": 0.6463990807533264,
      "learning_rate": 7.850678733031674e-05,
      "loss": 0.0526,
      "step": 380
    },
    {
      "epoch": 0.44092707744488413,
      "grad_norm": 0.7403039932250977,
      "learning_rate": 7.794117647058824e-05,
      "loss": 0.0477,
      "step": 390
    },
    {
      "epoch": 0.4522328999434709,
      "grad_norm": 0.47252604365348816,
      "learning_rate": 7.737556561085974e-05,
      "loss": 0.0505,
      "step": 400
    },
    {
      "epoch": 0.4635387224420577,
      "grad_norm": 0.228780135512352,
      "learning_rate": 7.680995475113123e-05,
      "loss": 0.0472,
      "step": 410
    },
    {
      "epoch": 0.47484454494064443,
      "grad_norm": 0.7029057741165161,
      "learning_rate": 7.624434389140271e-05,
      "loss": 0.0508,
      "step": 420
    },
    {
      "epoch": 0.4861503674392312,
      "grad_norm": 0.5056055784225464,
      "learning_rate": 7.567873303167421e-05,
      "loss": 0.0871,
      "step": 430
    },
    {
      "epoch": 0.497456189937818,
      "grad_norm": 0.2992648184299469,
      "learning_rate": 7.511312217194571e-05,
      "loss": 0.0523,
      "step": 440
    },
    {
      "epoch": 0.5087620124364047,
      "grad_norm": 0.5108587741851807,
      "learning_rate": 7.45475113122172e-05,
      "loss": 0.0401,
      "step": 450
    },
    {
      "epoch": 0.5200678349349915,
      "grad_norm": 0.5572494864463806,
      "learning_rate": 7.398190045248869e-05,
      "loss": 0.0487,
      "step": 460
    },
    {
      "epoch": 0.5313736574335783,
      "grad_norm": 0.40040937066078186,
      "learning_rate": 7.341628959276018e-05,
      "loss": 0.0523,
      "step": 470
    },
    {
      "epoch": 0.542679479932165,
      "grad_norm": 0.4428374767303467,
      "learning_rate": 7.285067873303167e-05,
      "loss": 0.051,
      "step": 480
    },
    {
      "epoch": 0.5539853024307518,
      "grad_norm": 0.5894176363945007,
      "learning_rate": 7.228506787330317e-05,
      "loss": 0.0551,
      "step": 490
    },
    {
      "epoch": 0.5652911249293386,
      "grad_norm": 0.5254224538803101,
      "learning_rate": 7.171945701357467e-05,
      "loss": 0.0538,
      "step": 500
    },
    {
      "epoch": 0.5765969474279253,
      "grad_norm": 0.503007173538208,
      "learning_rate": 7.115384615384616e-05,
      "loss": 0.0361,
      "step": 510
    },
    {
      "epoch": 0.5879027699265121,
      "grad_norm": 0.20366744697093964,
      "learning_rate": 7.058823529411765e-05,
      "loss": 0.038,
      "step": 520
    },
    {
      "epoch": 0.5992085924250989,
      "grad_norm": 0.41521114110946655,
      "learning_rate": 7.002262443438914e-05,
      "loss": 0.0606,
      "step": 530
    },
    {
      "epoch": 0.6105144149236857,
      "grad_norm": 0.7440342307090759,
      "learning_rate": 6.945701357466064e-05,
      "loss": 0.0503,
      "step": 540
    },
    {
      "epoch": 0.6218202374222724,
      "grad_norm": 0.5117661356925964,
      "learning_rate": 6.889140271493212e-05,
      "loss": 0.0592,
      "step": 550
    },
    {
      "epoch": 0.6331260599208592,
      "grad_norm": 0.20890899002552032,
      "learning_rate": 6.832579185520362e-05,
      "loss": 0.0394,
      "step": 560
    },
    {
      "epoch": 0.644431882419446,
      "grad_norm": 0.37216317653656006,
      "learning_rate": 6.776018099547512e-05,
      "loss": 0.0333,
      "step": 570
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.5263232588768005,
      "learning_rate": 6.719457013574662e-05,
      "loss": 0.0351,
      "step": 580
    },
    {
      "epoch": 0.6670435274166195,
      "grad_norm": 0.3571467697620392,
      "learning_rate": 6.66289592760181e-05,
      "loss": 0.0314,
      "step": 590
    },
    {
      "epoch": 0.6783493499152063,
      "grad_norm": 1.1849251985549927,
      "learning_rate": 6.606334841628959e-05,
      "loss": 0.0558,
      "step": 600
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.6529349088668823,
      "learning_rate": 6.549773755656109e-05,
      "loss": 0.0432,
      "step": 610
    },
    {
      "epoch": 0.7009609949123798,
      "grad_norm": 0.5217703580856323,
      "learning_rate": 6.493212669683258e-05,
      "loss": 0.057,
      "step": 620
    },
    {
      "epoch": 0.7122668174109666,
      "grad_norm": 0.4615226089954376,
      "learning_rate": 6.436651583710408e-05,
      "loss": 0.0292,
      "step": 630
    },
    {
      "epoch": 0.7235726399095535,
      "grad_norm": 0.7857714295387268,
      "learning_rate": 6.380090497737557e-05,
      "loss": 0.0478,
      "step": 640
    },
    {
      "epoch": 0.7348784624081401,
      "grad_norm": 0.633795976638794,
      "learning_rate": 6.323529411764705e-05,
      "loss": 0.0408,
      "step": 650
    },
    {
      "epoch": 0.746184284906727,
      "grad_norm": 0.5846021175384521,
      "learning_rate": 6.266968325791855e-05,
      "loss": 0.0534,
      "step": 660
    },
    {
      "epoch": 0.7574901074053138,
      "grad_norm": 0.8379735946655273,
      "learning_rate": 6.210407239819005e-05,
      "loss": 0.0468,
      "step": 670
    },
    {
      "epoch": 0.7687959299039006,
      "grad_norm": 0.4669826328754425,
      "learning_rate": 6.153846153846155e-05,
      "loss": 0.0532,
      "step": 680
    },
    {
      "epoch": 0.7801017524024872,
      "grad_norm": 0.5057278871536255,
      "learning_rate": 6.097285067873304e-05,
      "loss": 0.0364,
      "step": 690
    },
    {
      "epoch": 0.791407574901074,
      "grad_norm": 0.45614245533943176,
      "learning_rate": 6.0407239819004525e-05,
      "loss": 0.0392,
      "step": 700
    },
    {
      "epoch": 0.8027133973996609,
      "grad_norm": 0.40115416049957275,
      "learning_rate": 5.984162895927602e-05,
      "loss": 0.0431,
      "step": 710
    },
    {
      "epoch": 0.8140192198982475,
      "grad_norm": 0.5991466641426086,
      "learning_rate": 5.9276018099547516e-05,
      "loss": 0.0521,
      "step": 720
    },
    {
      "epoch": 0.8253250423968344,
      "grad_norm": 0.5092165470123291,
      "learning_rate": 5.871040723981901e-05,
      "loss": 0.0518,
      "step": 730
    },
    {
      "epoch": 0.8366308648954212,
      "grad_norm": 0.4294959306716919,
      "learning_rate": 5.8144796380090506e-05,
      "loss": 0.0383,
      "step": 740
    },
    {
      "epoch": 0.847936687394008,
      "grad_norm": 0.624837338924408,
      "learning_rate": 5.757918552036199e-05,
      "loss": 0.0492,
      "step": 750
    },
    {
      "epoch": 0.8592425098925947,
      "grad_norm": 0.6146548390388489,
      "learning_rate": 5.701357466063348e-05,
      "loss": 0.0527,
      "step": 760
    },
    {
      "epoch": 0.8705483323911815,
      "grad_norm": 0.4858262836933136,
      "learning_rate": 5.644796380090498e-05,
      "loss": 0.0365,
      "step": 770
    },
    {
      "epoch": 0.8818541548897683,
      "grad_norm": 0.5251266360282898,
      "learning_rate": 5.588235294117647e-05,
      "loss": 0.0587,
      "step": 780
    },
    {
      "epoch": 0.893159977388355,
      "grad_norm": 0.6133573055267334,
      "learning_rate": 5.531674208144797e-05,
      "loss": 0.0355,
      "step": 790
    },
    {
      "epoch": 0.9044657998869418,
      "grad_norm": 0.6339415311813354,
      "learning_rate": 5.475113122171946e-05,
      "loss": 0.0483,
      "step": 800
    },
    {
      "epoch": 0.9157716223855286,
      "grad_norm": 0.8393496870994568,
      "learning_rate": 5.418552036199095e-05,
      "loss": 0.0381,
      "step": 810
    },
    {
      "epoch": 0.9270774448841154,
      "grad_norm": 0.4667363166809082,
      "learning_rate": 5.3619909502262446e-05,
      "loss": 0.0332,
      "step": 820
    },
    {
      "epoch": 0.9383832673827021,
      "grad_norm": 0.43989014625549316,
      "learning_rate": 5.305429864253394e-05,
      "loss": 0.0603,
      "step": 830
    },
    {
      "epoch": 0.9496890898812889,
      "grad_norm": 0.851378321647644,
      "learning_rate": 5.2488687782805436e-05,
      "loss": 0.0381,
      "step": 840
    },
    {
      "epoch": 0.9609949123798757,
      "grad_norm": 0.5978864431381226,
      "learning_rate": 5.192307692307693e-05,
      "loss": 0.045,
      "step": 850
    },
    {
      "epoch": 0.9723007348784624,
      "grad_norm": 0.3160828649997711,
      "learning_rate": 5.135746606334841e-05,
      "loss": 0.035,
      "step": 860
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 0.385204553604126,
      "learning_rate": 5.079185520361991e-05,
      "loss": 0.0419,
      "step": 870
    },
    {
      "epoch": 0.994912379875636,
      "grad_norm": 0.34345826506614685,
      "learning_rate": 5.02262443438914e-05,
      "loss": 0.0282,
      "step": 880
    },
    {
      "epoch": 1.0056529112492933,
      "grad_norm": 0.2791922092437744,
      "learning_rate": 4.96606334841629e-05,
      "loss": 0.0332,
      "step": 890
    },
    {
      "epoch": 1.0169587337478803,
      "grad_norm": 1.1009200811386108,
      "learning_rate": 4.9095022624434386e-05,
      "loss": 0.0338,
      "step": 900
    },
    {
      "epoch": 1.028264556246467,
      "grad_norm": 0.4384230375289917,
      "learning_rate": 4.8529411764705885e-05,
      "loss": 0.0326,
      "step": 910
    },
    {
      "epoch": 1.0395703787450536,
      "grad_norm": 0.32379353046417236,
      "learning_rate": 4.7963800904977377e-05,
      "loss": 0.0295,
      "step": 920
    },
    {
      "epoch": 1.0508762012436406,
      "grad_norm": 0.7045598030090332,
      "learning_rate": 4.739819004524887e-05,
      "loss": 0.0282,
      "step": 930
    },
    {
      "epoch": 1.0621820237422273,
      "grad_norm": 0.20220012962818146,
      "learning_rate": 4.683257918552037e-05,
      "loss": 0.0188,
      "step": 940
    },
    {
      "epoch": 1.073487846240814,
      "grad_norm": 0.4246031939983368,
      "learning_rate": 4.626696832579186e-05,
      "loss": 0.0195,
      "step": 950
    },
    {
      "epoch": 1.0847936687394009,
      "grad_norm": 0.6820128560066223,
      "learning_rate": 4.570135746606335e-05,
      "loss": 0.0386,
      "step": 960
    },
    {
      "epoch": 1.0960994912379876,
      "grad_norm": 0.21175703406333923,
      "learning_rate": 4.513574660633484e-05,
      "loss": 0.0279,
      "step": 970
    },
    {
      "epoch": 1.1074053137365742,
      "grad_norm": 0.2381085604429245,
      "learning_rate": 4.457013574660634e-05,
      "loss": 0.0216,
      "step": 980
    },
    {
      "epoch": 1.1187111362351612,
      "grad_norm": 0.3297716975212097,
      "learning_rate": 4.400452488687783e-05,
      "loss": 0.0396,
      "step": 990
    },
    {
      "epoch": 1.1300169587337479,
      "grad_norm": 0.5968059301376343,
      "learning_rate": 4.3438914027149324e-05,
      "loss": 0.0262,
      "step": 1000
    },
    {
      "epoch": 1.1413227812323345,
      "grad_norm": 0.20556208491325378,
      "learning_rate": 4.2873303167420815e-05,
      "loss": 0.0309,
      "step": 1010
    },
    {
      "epoch": 1.1526286037309215,
      "grad_norm": 0.37614238262176514,
      "learning_rate": 4.230769230769231e-05,
      "loss": 0.0324,
      "step": 1020
    },
    {
      "epoch": 1.1639344262295082,
      "grad_norm": 0.2499644011259079,
      "learning_rate": 4.1742081447963806e-05,
      "loss": 0.0365,
      "step": 1030
    },
    {
      "epoch": 1.175240248728095,
      "grad_norm": 0.31928807497024536,
      "learning_rate": 4.11764705882353e-05,
      "loss": 0.021,
      "step": 1040
    },
    {
      "epoch": 1.1865460712266818,
      "grad_norm": 0.21716514229774475,
      "learning_rate": 4.061085972850679e-05,
      "loss": 0.0292,
      "step": 1050
    },
    {
      "epoch": 1.1978518937252685,
      "grad_norm": 0.13898232579231262,
      "learning_rate": 4.004524886877829e-05,
      "loss": 0.026,
      "step": 1060
    },
    {
      "epoch": 1.2091577162238554,
      "grad_norm": 0.536152720451355,
      "learning_rate": 3.947963800904977e-05,
      "loss": 0.029,
      "step": 1070
    },
    {
      "epoch": 1.220463538722442,
      "grad_norm": 0.30439168214797974,
      "learning_rate": 3.891402714932127e-05,
      "loss": 0.0298,
      "step": 1080
    },
    {
      "epoch": 1.2317693612210288,
      "grad_norm": 0.3429849445819855,
      "learning_rate": 3.834841628959276e-05,
      "loss": 0.0181,
      "step": 1090
    },
    {
      "epoch": 1.2430751837196157,
      "grad_norm": 0.06957045942544937,
      "learning_rate": 3.7782805429864254e-05,
      "loss": 0.0242,
      "step": 1100
    },
    {
      "epoch": 1.2543810062182024,
      "grad_norm": 0.521323561668396,
      "learning_rate": 3.721719457013575e-05,
      "loss": 0.0304,
      "step": 1110
    },
    {
      "epoch": 1.265686828716789,
      "grad_norm": 0.5541322231292725,
      "learning_rate": 3.665158371040724e-05,
      "loss": 0.0221,
      "step": 1120
    },
    {
      "epoch": 1.276992651215376,
      "grad_norm": 0.7443575263023376,
      "learning_rate": 3.6085972850678736e-05,
      "loss": 0.0316,
      "step": 1130
    },
    {
      "epoch": 1.2882984737139627,
      "grad_norm": 0.5019176602363586,
      "learning_rate": 3.552036199095023e-05,
      "loss": 0.0166,
      "step": 1140
    },
    {
      "epoch": 1.2996042962125496,
      "grad_norm": 0.19631828367710114,
      "learning_rate": 3.495475113122172e-05,
      "loss": 0.0338,
      "step": 1150
    },
    {
      "epoch": 1.3109101187111363,
      "grad_norm": 0.5111569166183472,
      "learning_rate": 3.438914027149321e-05,
      "loss": 0.0353,
      "step": 1160
    },
    {
      "epoch": 1.322215941209723,
      "grad_norm": 0.1359167844057083,
      "learning_rate": 3.382352941176471e-05,
      "loss": 0.0243,
      "step": 1170
    },
    {
      "epoch": 1.3335217637083097,
      "grad_norm": 0.32775232195854187,
      "learning_rate": 3.32579185520362e-05,
      "loss": 0.027,
      "step": 1180
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.526081919670105,
      "learning_rate": 3.269230769230769e-05,
      "loss": 0.0161,
      "step": 1190
    },
    {
      "epoch": 1.3561334087054833,
      "grad_norm": 0.21239225566387177,
      "learning_rate": 3.212669683257919e-05,
      "loss": 0.0258,
      "step": 1200
    },
    {
      "epoch": 1.3674392312040702,
      "grad_norm": 0.4707598090171814,
      "learning_rate": 3.1561085972850676e-05,
      "loss": 0.0286,
      "step": 1210
    },
    {
      "epoch": 1.3787450537026569,
      "grad_norm": 0.4683396816253662,
      "learning_rate": 3.0995475113122175e-05,
      "loss": 0.018,
      "step": 1220
    },
    {
      "epoch": 1.3900508762012436,
      "grad_norm": 0.44074881076812744,
      "learning_rate": 3.0429864253393663e-05,
      "loss": 0.0269,
      "step": 1230
    },
    {
      "epoch": 1.4013566986998305,
      "grad_norm": 0.5476645827293396,
      "learning_rate": 2.986425339366516e-05,
      "loss": 0.0286,
      "step": 1240
    },
    {
      "epoch": 1.4126625211984172,
      "grad_norm": 0.5300520062446594,
      "learning_rate": 2.9298642533936653e-05,
      "loss": 0.0162,
      "step": 1250
    },
    {
      "epoch": 1.423968343697004,
      "grad_norm": 0.43385255336761475,
      "learning_rate": 2.8733031674208145e-05,
      "loss": 0.0228,
      "step": 1260
    },
    {
      "epoch": 1.4352741661955908,
      "grad_norm": 0.6519704461097717,
      "learning_rate": 2.816742081447964e-05,
      "loss": 0.0379,
      "step": 1270
    },
    {
      "epoch": 1.4465799886941775,
      "grad_norm": 0.6099923849105835,
      "learning_rate": 2.7601809954751135e-05,
      "loss": 0.0243,
      "step": 1280
    },
    {
      "epoch": 1.4578858111927642,
      "grad_norm": 0.1732727438211441,
      "learning_rate": 2.7036199095022624e-05,
      "loss": 0.0208,
      "step": 1290
    },
    {
      "epoch": 1.469191633691351,
      "grad_norm": 0.647013783454895,
      "learning_rate": 2.647058823529412e-05,
      "loss": 0.0214,
      "step": 1300
    },
    {
      "epoch": 1.4804974561899378,
      "grad_norm": 0.7521613240242004,
      "learning_rate": 2.5904977375565614e-05,
      "loss": 0.0278,
      "step": 1310
    },
    {
      "epoch": 1.4918032786885247,
      "grad_norm": 0.2211199402809143,
      "learning_rate": 2.5339366515837106e-05,
      "loss": 0.0309,
      "step": 1320
    },
    {
      "epoch": 1.5031091011871114,
      "grad_norm": 0.2017025649547577,
      "learning_rate": 2.47737556561086e-05,
      "loss": 0.0171,
      "step": 1330
    },
    {
      "epoch": 1.514414923685698,
      "grad_norm": 0.15373244881629944,
      "learning_rate": 2.4208144796380092e-05,
      "loss": 0.0253,
      "step": 1340
    },
    {
      "epoch": 1.5257207461842848,
      "grad_norm": 0.1310623437166214,
      "learning_rate": 2.3642533936651584e-05,
      "loss": 0.0242,
      "step": 1350
    },
    {
      "epoch": 1.5370265686828717,
      "grad_norm": 0.21730858087539673,
      "learning_rate": 2.307692307692308e-05,
      "loss": 0.0223,
      "step": 1360
    },
    {
      "epoch": 1.5483323911814586,
      "grad_norm": 1.5201925039291382,
      "learning_rate": 2.251131221719457e-05,
      "loss": 0.0189,
      "step": 1370
    },
    {
      "epoch": 1.5596382136800453,
      "grad_norm": 0.45480793714523315,
      "learning_rate": 2.1945701357466062e-05,
      "loss": 0.024,
      "step": 1380
    },
    {
      "epoch": 1.570944036178632,
      "grad_norm": 0.255243718624115,
      "learning_rate": 2.1380090497737558e-05,
      "loss": 0.039,
      "step": 1390
    },
    {
      "epoch": 1.5822498586772187,
      "grad_norm": 0.5196892023086548,
      "learning_rate": 2.0814479638009053e-05,
      "loss": 0.0153,
      "step": 1400
    },
    {
      "epoch": 1.5935556811758056,
      "grad_norm": 0.35122746229171753,
      "learning_rate": 2.0248868778280544e-05,
      "loss": 0.0326,
      "step": 1410
    },
    {
      "epoch": 1.6048615036743923,
      "grad_norm": 0.7658254504203796,
      "learning_rate": 1.9683257918552036e-05,
      "loss": 0.0217,
      "step": 1420
    },
    {
      "epoch": 1.6161673261729792,
      "grad_norm": 0.4019926190376282,
      "learning_rate": 1.9117647058823528e-05,
      "loss": 0.0438,
      "step": 1430
    },
    {
      "epoch": 1.627473148671566,
      "grad_norm": 0.15831993520259857,
      "learning_rate": 1.8552036199095023e-05,
      "loss": 0.0208,
      "step": 1440
    },
    {
      "epoch": 1.6387789711701526,
      "grad_norm": 0.3203544020652771,
      "learning_rate": 1.7986425339366518e-05,
      "loss": 0.0255,
      "step": 1450
    },
    {
      "epoch": 1.6500847936687393,
      "grad_norm": 0.2897462844848633,
      "learning_rate": 1.742081447963801e-05,
      "loss": 0.0301,
      "step": 1460
    },
    {
      "epoch": 1.6613906161673262,
      "grad_norm": 0.5850411653518677,
      "learning_rate": 1.6855203619909505e-05,
      "loss": 0.0339,
      "step": 1470
    },
    {
      "epoch": 1.672696438665913,
      "grad_norm": 0.5423589944839478,
      "learning_rate": 1.6289592760180996e-05,
      "loss": 0.0261,
      "step": 1480
    },
    {
      "epoch": 1.6840022611644998,
      "grad_norm": 0.42133086919784546,
      "learning_rate": 1.5723981900452488e-05,
      "loss": 0.0227,
      "step": 1490
    },
    {
      "epoch": 1.6953080836630865,
      "grad_norm": 0.6541538238525391,
      "learning_rate": 1.5158371040723981e-05,
      "loss": 0.0235,
      "step": 1500
    },
    {
      "epoch": 1.7066139061616732,
      "grad_norm": 0.5977542996406555,
      "learning_rate": 1.4592760180995477e-05,
      "loss": 0.0229,
      "step": 1510
    },
    {
      "epoch": 1.7179197286602599,
      "grad_norm": 0.8822375535964966,
      "learning_rate": 1.402714932126697e-05,
      "loss": 0.0219,
      "step": 1520
    },
    {
      "epoch": 1.7292255511588468,
      "grad_norm": 0.5944744944572449,
      "learning_rate": 1.3461538461538462e-05,
      "loss": 0.0324,
      "step": 1530
    },
    {
      "epoch": 1.7405313736574337,
      "grad_norm": 0.9193214774131775,
      "learning_rate": 1.2895927601809957e-05,
      "loss": 0.0235,
      "step": 1540
    },
    {
      "epoch": 1.7518371961560204,
      "grad_norm": 0.748359739780426,
      "learning_rate": 1.2330316742081448e-05,
      "loss": 0.015,
      "step": 1550
    },
    {
      "epoch": 1.763143018654607,
      "grad_norm": 0.8345755934715271,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 0.0284,
      "step": 1560
    },
    {
      "epoch": 1.7744488411531938,
      "grad_norm": 0.07611104846000671,
      "learning_rate": 1.1199095022624435e-05,
      "loss": 0.0295,
      "step": 1570
    },
    {
      "epoch": 1.7857546636517807,
      "grad_norm": 0.48778560757637024,
      "learning_rate": 1.0633484162895929e-05,
      "loss": 0.0163,
      "step": 1580
    },
    {
      "epoch": 1.7970604861503674,
      "grad_norm": 0.558807373046875,
      "learning_rate": 1.0067873303167422e-05,
      "loss": 0.0314,
      "step": 1590
    },
    {
      "epoch": 1.8083663086489543,
      "grad_norm": 0.38389167189598083,
      "learning_rate": 9.502262443438914e-06,
      "loss": 0.0288,
      "step": 1600
    },
    {
      "epoch": 1.819672131147541,
      "grad_norm": 0.5253997445106506,
      "learning_rate": 8.936651583710407e-06,
      "loss": 0.0242,
      "step": 1610
    },
    {
      "epoch": 1.8309779536461277,
      "grad_norm": 0.24119000136852264,
      "learning_rate": 8.3710407239819e-06,
      "loss": 0.0172,
      "step": 1620
    },
    {
      "epoch": 1.8422837761447144,
      "grad_norm": 0.5132172107696533,
      "learning_rate": 7.805429864253394e-06,
      "loss": 0.0244,
      "step": 1630
    },
    {
      "epoch": 1.8535895986433013,
      "grad_norm": 0.43018147349357605,
      "learning_rate": 7.239819004524888e-06,
      "loss": 0.0227,
      "step": 1640
    },
    {
      "epoch": 1.8648954211418882,
      "grad_norm": 0.2160513699054718,
      "learning_rate": 6.674208144796381e-06,
      "loss": 0.0269,
      "step": 1650
    },
    {
      "epoch": 1.876201243640475,
      "grad_norm": 0.16042360663414001,
      "learning_rate": 6.108597285067873e-06,
      "loss": 0.02,
      "step": 1660
    },
    {
      "epoch": 1.8875070661390616,
      "grad_norm": 0.7486209273338318,
      "learning_rate": 5.542986425339367e-06,
      "loss": 0.0251,
      "step": 1670
    },
    {
      "epoch": 1.8988128886376483,
      "grad_norm": 0.2415393739938736,
      "learning_rate": 4.97737556561086e-06,
      "loss": 0.0234,
      "step": 1680
    },
    {
      "epoch": 1.9101187111362352,
      "grad_norm": 0.15601451694965363,
      "learning_rate": 4.411764705882353e-06,
      "loss": 0.0167,
      "step": 1690
    },
    {
      "epoch": 1.921424533634822,
      "grad_norm": 0.32101330161094666,
      "learning_rate": 3.846153846153847e-06,
      "loss": 0.0329,
      "step": 1700
    },
    {
      "epoch": 1.9327303561334088,
      "grad_norm": 0.4589138329029083,
      "learning_rate": 3.2805429864253398e-06,
      "loss": 0.0208,
      "step": 1710
    },
    {
      "epoch": 1.9440361786319955,
      "grad_norm": 0.43641752004623413,
      "learning_rate": 2.7149321266968327e-06,
      "loss": 0.0176,
      "step": 1720
    },
    {
      "epoch": 1.9553420011305822,
      "grad_norm": 0.4899371266365051,
      "learning_rate": 2.1493212669683257e-06,
      "loss": 0.0319,
      "step": 1730
    },
    {
      "epoch": 1.966647823629169,
      "grad_norm": 0.5157656669616699,
      "learning_rate": 1.583710407239819e-06,
      "loss": 0.0234,
      "step": 1740
    },
    {
      "epoch": 1.9779536461277558,
      "grad_norm": 0.6767973303794861,
      "learning_rate": 1.0180995475113123e-06,
      "loss": 0.026,
      "step": 1750
    },
    {
      "epoch": 1.9892594686263427,
      "grad_norm": 0.20091280341148376,
      "learning_rate": 4.524886877828055e-07,
      "loss": 0.0194,
      "step": 1760
    }
  ],
  "logging_steps": 10,
  "max_steps": 1768,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.876475797529805e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
